{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.99.3)\n",
      "Requirement already satisfied: langchain in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.3.27)\n",
      "Requirement already satisfied: langchain_openai in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.3.28)\n",
      "Requirement already satisfied: langchain_experimental in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.3.4)\n",
      "Requirement already satisfied: langchainhub in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.1.21)\n",
      "Requirement already satisfied: pinecone-client in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (6.0.0)\n",
      "Requirement already satisfied: python-dotenv in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: tiktoken in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.10.0)\n",
      "Requirement already satisfied: docx2txt in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.9)\n",
      "Requirement already satisfied: pypdf in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.32.4)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.2.6)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./env/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./env/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./env/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./env/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (2.11.7)\n",
      "Requirement already satisfied: sniffio in ./env/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./env/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./env/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi in ./env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./env/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./env/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./env/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./env/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (0.4.13)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./env/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (2.0.42)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./env/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./env/lib/python3.10/site-packages (from requests->-r requirements.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.10/site-packages (from requests->-r requirements.txt (line 11)) (2.5.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./env/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 2)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 2)) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in ./env/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./env/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./env/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 8)) (2025.7.34)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in ./env/lib/python3.10/site-packages (from langchain_experimental->-r requirements.txt (line 4)) (0.3.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./env/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./env/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./env/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./env/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./env/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in ./env/lib/python3.10/site-packages (from langchainhub->-r requirements.txt (line 5)) (2.32.4.20250611)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./env/lib/python3.10/site-packages (from pinecone-client->-r requirements.txt (line 6)) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./env/lib/python3.10/site-packages (from pinecone-client->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 13)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 13)) (2025.2)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone-client->-r requirements.txt (line 6)) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.99.3\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /home/prashantdpaisa/Downloads/GenAI Roadmap/Udemy - LangChain MasteryDevelop LLM Apps with LangChain & Pinecone 2024-5/GENAI/env/lib/python3.10/site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: langchain-openai\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.27\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/prashantdpaisa/Downloads/GenAI Roadmap/Udemy - LangChain MasteryDevelop LLM Apps with LangChain & Pinecone 2024-5/GENAI/env/lib/python3.10/site-packages\n",
      "Requires: async-timeout, langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: langchain-community\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "os.environ.get('OPENROUTER_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI( \n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    temperature=0, \n",
    "    request_timeout=20\n",
    "    )\n",
    "output = llm.invoke(\"What is the capital of France?\")\n",
    "print(output.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(ChatOpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "क्वान्टम भौतिक तथ्यहरूलाई सरल शब्दमा समझाउँछ। यसले छोटो र अत्यन्त सूक्ष्म रूपमा भौतिक तथ्यहरूको अध्ययन गर्दछ। यसले भौतिक विश्वको अद्भुतता र असाधारणतालाई अध्ययन गर्दछ जसले हामीलाई नयाँ धारणाहरू ल्याउँछ।\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import(SystemMessage, HumanMessage, AIMessage)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a physicist and only respon in nepali.\"),\n",
    "    HumanMessage(content=\"Expalin quantam physics in simple terms.\"),\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching  LLM Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Memory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.59 ms, sys: 1.99 ms, total: 11.6 ms\n",
      "Wall time: 4.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the cookie go to the doctor? Because it was feeling crumbly!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 17, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'openai/gpt-3.5-turbo', 'system_fingerprint': None, 'id': 'gen-1754803026-gTQuc7JDIrcBMtkhXxx4', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--1fe0eb27-9a24-44cc-b8c3-ac828f7bfcc7-0', usage_metadata={'input_tokens': 17, 'output_tokens': 17, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = \"Tell me a joke that a toddler can understand.\"\n",
    "llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 545 μs, sys: 41 μs, total: 586 μs\n",
      "Wall time: 582 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the cookie go to the doctor? Because it was feeling crumbly!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 17, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'openai/gpt-3.5-turbo', 'system_fingerprint': None, 'id': 'gen-1754803026-gTQuc7JDIrcBMtkhXxx4', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--1fe0eb27-9a24-44cc-b8c3-ac828f7bfcc7-0', usage_metadata={'input_tokens': 17, 'output_tokens': 17, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}, 'total_cost': 0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLITE CACHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why couldn't the bicycle stand up by itself? Because it was two tired!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 12, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'openai/gpt-3.5-turbo', 'system_fingerprint': None, 'id': 'gen-1754811473-7Vz7cGEuogZpfB4k841B', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--75f65f0f-d395-4c34-96ab-b94cc6cf9db8-0', usage_metadata={'input_tokens': 12, 'output_tokens': 16, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}, 'total_cost': 0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "set_llm_cache(SQLiteCache(database_path=\"cache.db\"))\n",
    "\n",
    "# First request\n",
    "llm.invoke(\"Tell me a joke.\")\n",
    "\n",
    "#second request\n",
    "llm.invoke(\"Tell me a joke.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STREAMING\n",
    "#### Streaming refers to the process of sending the response in streams of contineous data instead of sending the entire response at once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "हाम्रो देश नेपाल, राम्रो छ सबैले भन्छन्\n",
      "हाम्रो सानो देश, धेरै छ खुशी र गम\n",
      "हाम्रो नेपाल, सुन्दर छ प्राकृतिक सौन्दर्य\n",
      "हाम्रो नेपाल, जन्मभूमि हाम्रो प्यारो\n",
      "\n",
      "Chorus:\n",
      "नेपाली हामी, एक छौं एकै भाषा\n",
      "नेपाली हामी, एक छौं एकै जाति\n",
      "नेपाली हामी, एक छौं एकै धर्म\n",
      "नेपाली हामी, एक छौं एकै राष्ट्र\n",
      "\n",
      "Verse 2:\n",
      "हाम्रो नेपाल, भिन्न भिन्न जाति भाषा\n",
      "तर हाम्रो एकता, छ अद्भुत साथी\n",
      "हाम्रो नेपाल, धेरै छ समृद्धि र सम्पत्ति\n",
      "हाम्रो नेपाल, जीवन भर रहोस् सुखी\n",
      "\n",
      "Chorus:\n",
      "नेपाली हामी, एक छौं एकै भाषा\n",
      "नेपाली हामी, एक छौं एकै जाति\n",
      "नेपाली हामी, एक छौं एकै धर्म\n",
      "नेपाली हामी, एक छौं एकै राष्ट्र\n",
      "\n",
      "Bridge:\n",
      "हाम्रो नेपाल, अन्तर्क्षमा फर्किएर\n",
      "हाम्रो नेपाल, उच्च उडान भर्दै\n",
      "हाम्रो नेपाल, सबैले गरौं यो संकल्प\n",
      "हाम्रो नेपाल, अब बढौं हाम्रो नेपाल\n",
      "\n",
      "Chorus:\n",
      "नेपाली हामी, एक छौं एकै भाषा\n",
      "नेपाली हामी, एक छौं एकै जाति\n",
      "नेपाली हामी, एक छौं एकै धर्म\n",
      "नेपाली हामी, एक छौं एकै राष्ट्र\n",
      "\n",
      "Outro:\n",
      "हाम्रो नेपाल, अनन्तकाल सुरक्षित रहोस्\n",
      "हाम्रो नेपाल, सदैव उज्वल रहोस्\n",
      "हाम्रो नेपाल, जय नेपाल! जय नेपाल!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)\n",
    "\n",
    "prompt=\"write a song in nepali?\"\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "हाम्रो देश नेपाल,\n",
      "हाम्रो गाउँ नेपाल,\n",
      "हाम्रो माया नेपाल,\n",
      "हाम्रो जिन्दगी नेपाल।\n",
      "\n",
      "Chorus:\n",
      "नेपाली हामी,\n",
      "एक छौं दिल रुमाली,\n",
      "साथी हाम्रो साथी,\n",
      "नेपाली हामी।\n",
      "\n",
      "Verse 2:\n",
      "हाम्रो भाषा नेपाली,\n",
      "हाम्रो संस्कृति नेपाली,\n",
      "हाम्रो गीत नेपाली,\n",
      "हाम्रो धरोहर नेपाली।\n",
      "\n",
      "Chorus:\n",
      "नेपाली हामी,\n",
      "एक छौं दिल रुमाली,\n",
      "साथी हाम्रो साथी,\n",
      "नेपाली हामी।\n",
      "\n",
      "Bridge:\n",
      "हाम्रो देश नेपाल,\n",
      "हाम्रो गाउँ नेपाल,\n",
      "हाम्रो माया नेपाल,\n",
      "हाम्रो जिन्दगी नेपाल।\n",
      "\n",
      "Chorus:\n",
      "नेपाली हामी,\n",
      "एक छौं दिल रुमाली,\n",
      "साथी हाम्रो साथी,\n",
      "नेपाली हामी।\n",
      "\n",
      "Outro:\n",
      "नेपाली हामी,\n",
      "एक छौं दिल रुमाली,\n",
      "साथी हाम्रो साथी,\n",
      "नेपाली हामी।"
     ]
    }
   ],
   "source": [
    "for chuck in llm.stream(prompt):\n",
    "    print(chuck.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROMPT, PROMPT TEMPLATES\n",
    "#### Prompt refers to the imput to the model.\n",
    "#### Prompt Templates are way to create dyanmic prompt for LLMs.\n",
    "#### A prompt template takes a piece of text and injects a user's input into that piece of text. \n",
    "#### In langchain there are  Prompt Templates and ChainPromptTemplates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROMPT TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert virologist.\\nWrite a few sentence about the following virus \"COVID-19\" in nepali.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = \"\"\"You are an expert virologist.\n",
    "Write a few sentence about the following virus \"{virus_name}\" in {language}.\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt = prompt_template.format(virus_name=\"COVID-19\", language=\"nepali\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कोभिड-१९ भाइरस एक गम्भीर वायरस हो जसले मानिसहरूको फेफडा र श्वासन प्रणालीमा संक्रमण गर्दछ। यस वायरसले विश्वभरि लाखौं मानिसहरूलाई संक्रमित गरेको छ र यसको कारण बनेको लागि विश्व स्वास्थ्य संगठनले यसलाई एक महामारी घोषणा गरेको छ। यस वायरसले विश्वभरि अर्थतन्त्र र सामाजिक जीवनमा धेरै प्रभाव गरेको छ।\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in json format.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Top 5 countries in Europe by population,', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You respond only in json format.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"Top {n} countries in {area} by population,\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(n=5, area=\"Europe\")\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": \"Germany\",\n",
      "    \"2\": \"France\",\n",
      "    \"3\": \"United Kingdom\",\n",
      "    \"4\": \"Italy\",\n",
      "    \"5\": \"Spain\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "llm = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Chains\n",
    "Chains allows  us to combine multiple components together to solve a specific task and build an entire LLM application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'virus_name': 'HSV', 'language': 'nepali', 'text': 'HSV भनेको हेरपेस सिम्प्लेक्स भाइरसको संक्रमण हो। यसले मुख, नाक र आँखाको चारोमा देखिने लाग्छ र यसले जननाङ्गको चारोमा पनि संक्रमण गर्न सक्दछ। यसले जनसंख्यामा धेरै प्रभाव गर्दछ र यसको उपचार गर्नका लागि डोसिलाइकल औषधि प्रयोग गरिन्छ।'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import  ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "llm = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)   \n",
    "template = \"\"\"You are an expert virologist.\n",
    "Write a few sentence about the following virus \"{virus_name}\" in {language}.\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_template\n",
    "    )\n",
    "\n",
    "output = chain.invoke({'virus_name' : 'HSV', 'language': 'nepali'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is the capital of nepal?. List the top three places to visit in that city. Use bullet points.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The capital of Nepal is Kathmandu.\n",
      "\n",
      "Top three places to visit in Kathmandu:\n",
      "- Swayambhunath Stupa (Monkey Temple)\n",
      "- Boudhanath Stupa\n",
      "- Durbar Square\n"
     ]
    }
   ],
   "source": [
    "template = \"What is the capital of {country}?. List the top three places to visit in that city. Use bullet points.\"\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "country = input(\"Enter a country name: \")\n",
    "output = chain.invoke(country)\n",
    "print(output['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chains\n",
    "With sequential chain, you can make a series of calls to one or more LLMs. You can take the output from one\n",
    "chain and use it as the input to another chain.\n",
    "There are two types of sequential chains\n",
    "1. Simple sequential Chains\n",
    "2. General from of sequential chains\n",
    "\n",
    "Simple sequential chain represents a series of chains, where each individual chain  has a single input and a single output,\n",
    "and the output of one step is used as input to the next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6752/3726437078.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure! Here is an example of a Python function that implements recursion:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial(n-1)\n",
      "\n",
      "# Example usage\n",
      "result = factorial(5)\n",
      "print(result)  # Output: 120\n",
      "```\n",
      "\n",
      "In this example, the `factorial` function calculates the factorial of a given number `n` using recursion. The base case is when `n` is equal to 0, in which case the function returns 1. Otherwise, it recursively calls itself with `n-1` until it reaches the base case.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe `factorial` function is a recursive function that calculates the factorial of a given number `n`. \n",
      "\n",
      "1. The function takes an integer `n` as input.\n",
      "2. It checks if `n` is equal to 0. If it is, the function returns 1, which is the base case for the factorial function (0! = 1).\n",
      "3. If `n` is not equal to 0, the function recursively calls itself with the argument `n-1`. This means that the function will keep calling itself with decreasing values of `n` until it reaches the base case.\n",
      "4. Each recursive call multiplies the current value of `n` with the result of the factorial of `n-1`.\n",
      "5. Once the base case is reached (when `n` is equal to 0), the function starts returning the results of the multiplication operations back up the call stack.\n",
      "6. The final result is the factorial of the original input `n`.\n",
      "\n",
      "In the example provided, the `factorial` function is called with an input of 5 (`factorial(5)`), which calculates `5!` recursively. The result is then printed, which in this case is 120.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "import os\n",
    "\n",
    "llm1 = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)\n",
    "prompt_template1 = PromptTemplate.from_template(template=\"You are an experienced scientist and Python programmer. Write a function that implements the concept of  {concept}.\")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "llm2 = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)  \n",
    "prompt_template2 = PromptTemplate.from_template(template=\"Given the python function {function}, describe it as detailed as possible.\")   \n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.invoke(\"recursion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `factorial` function is a recursive function that calculates the factorial of a given number `n`. \n",
      "\n",
      "1. The function takes an integer `n` as input.\n",
      "2. It checks if `n` is equal to 0. If it is, the function returns 1, which is the base case for the factorial function (0! = 1).\n",
      "3. If `n` is not equal to 0, the function recursively calls itself with the argument `n-1`. This means that the function will keep calling itself with decreasing values of `n` until it reaches the base case.\n",
      "4. Each recursive call multiplies the current value of `n` with the result of the factorial of `n-1`.\n",
      "5. Once the base case is reached (when `n` is equal to 0), the function starts returning the results of the multiplication operations back up the call stack.\n",
      "6. The final result is the factorial of the original input `n`.\n",
      "\n",
      "In the example provided, the `factorial` function is called with an input of 5 (`factorial(5)`), which calculates `5!` recursively. The result is then printed, which in this case is 120.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchian Agents \n",
    "#### LangChain Agents in Action: Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(1, 100) if n % 13 == 0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe can calculate the factorial of 12 first and then find the square root of that result. Finally, we can display it with 4 decimal points.\n",
      "Action: Python_REPL\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe need to import the math module to access the square root function.\n",
      "Action: Python_REPL\n",
      "Action Input: math.factorial(12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe have calculated the factorial of 12, now we can find the square root of this result.\n",
      "Action: Python_REPL\n",
      "Action Input: round(math.sqrt(math.factorial(12)), 4)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe square root of the factorial of 12, rounded to 4 decimal points, is approximately 89.4427.\n",
      "Final Answer: 89.4427\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the square root of factorial of 12 and display it with 4 decimal points',\n",
       " 'output': '89.4427'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)   \n",
    "agent_executer = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True,\n",
    ")\n",
    "agent_executer.invoke('Calculate the square root of factorial of 12 and display it with 4 decimal points')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe can calculate the result of 5.1 raised to the power of 7.3 using Python.\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe result of 5.1 raised to the power of 7.3 is 146306.05007233328.\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executer.invoke('What is the answer to 5.1 ** 7.3?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146306.05007233328\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the answer to 5.1 ** 7.3?\n"
     ]
    }
   ],
   "source": [
    "print(response['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LANGCHAIN TOOLS\n",
    "Langchain tools are like specialize app for you LLM. They are tiny code modules that allow it to access information and services.\n",
    "These tools connect your LLM to search engines, databases, APIs, and more, expanding its knowledge and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAGCHAIN TOOLS: DUCKDUCKGO AND WIKIPEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashantdpaisa/Downloads/GenAI Roadmap/Udemy - LangChain MasteryDevelop LLM Apps with LangChain & Pinecone 2024-5/GENAI/env/lib/python3.10/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn facts about France and see where France is located with a map. Explore the France population, the culture, geography of France, and other relevant facts. Dec 19, 2024 · París [pa.'ɾis] (capital of France) Paris ['pa.ɾis] (Hector's brother in The Iliad) *parís [pa.'ɾis] you (familiar plural / classic Spanish \"vos\" formal singular) give birth: vosotras parís ... Aug 30, 2023 · The Letter 'N' : London France ^ ^ ------->^The words pants and France do not rhyme because there is a t sound in pants which is not in France. If the word were Frants, it … Oct 18, 2022 · NO. Paris is in France, and is the capital there. The capital of Italy is Rome. Aug 31, 2023 · France did not exist as such in Roman times. Its territory was then divided in provinces, some extending over the borders we now have. For the Romans, Lyon (Lyons) was …\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()\n",
    "output = search.invoke(\"What is the capital of France?\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duckduckgo_search'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashantdpaisa/Downloads/GenAI Roadmap/Udemy - LangChain MasteryDevelop LLM Apps with LangChain & Pinecone 2024-5/GENAI/env/lib/python3.10/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "search = DuckDuckGoSearchResults()\n",
    "output = search.run(\"What is the capital of France?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashantdpaisa/Downloads/GenAI Roadmap/Udemy - LangChain MasteryDevelop LLM Apps with LangChain & Pinecone 2024-5/GENAI/env/lib/python3.10/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region=\"de-de\", max_results=3, safesearch='moderate')\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source='news')\n",
    "output = search.run(\"Berlin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippet: Log in to access your dashboard and manage HR tasks efficiently | Trusted since 2000. HRMS Software, Payroll Software, …, title: HRMantra Login, link: https://www.hrmantra.com/02/login, snippet: HRMantra Global offers advanced HR and payroll software solutions to streamline human resource management and …, title: HRMantra Global, link: https://hrmantra.com/HRMGlobal/HomePage/Home, snippet: AI driven voicebot with loads of readymade APIs to instantly connect with different third-party systems. Most …, title: HRMantra | The Ultimate HR Software Solution, link: https://www.hrmantra.com/default.aspx/login.aspx, snippet: The session expires automatically if the browser window is idle for a long time. If the problem persists, please try again after …, title: HRMantra Online, link: https://hrmantra.com/svcmpl/00_Common/HomePage.aspx\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "patterns = r'snippets: (.*?), title: (.*?), link: (.*?),]'\n",
    "matches = re.findall(patterns, output, re.DOTALL)\n",
    "\n",
    "for snipper, title, link in matches:\n",
    "    print(f\"Snipper: {snipper}\\nTitle: {title}\\nLink: {link}\\n\") \n",
    "    print('-', * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'wikipedia' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WikipediaQueryRun' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m api_wrapper \u001b[38;5;241m=\u001b[39m WikipediaAPIWrapper(top_k_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, doc_content_chars_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m      5\u001b[0m wiki \u001b[38;5;241m=\u001b[39m WikipediaQueryRun(api_wrapper\u001b[38;5;241m=\u001b[39mapi_wrapper)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mwiki\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllamaindex\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/Downloads/GenAI Roadmap/Udemy - LangChain MasteryDevelop LLM Apps with LangChain & Pinecone 2024-5/GENAI/env/lib/python3.10/site-packages/pydantic/main.py:991\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WikipediaQueryRun' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wiki.query.invoke({'query':'llamaindex'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct (Reasoning and Acting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "React is a new approach that combines reasoaning(chain of thoughts prompting) and acting capabilities of llm\n",
    "With ReAct LLMs generate reasoning traces and task-specific actions in an interleaved manner.\n",
    "Lagchain agents tools + Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating  a ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchainhub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashantdpaisa/Downloads/GenAI Roadmap/Udemy - LangChain MasteryDevelop LLM Apps with LangChain & Pinecone 2024-5/GENAI/env/lib/python3.10/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent\n",
    "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\"), temperature=0, request_timeout=20)\n",
    "\n",
    "# Define a template for answering questions\n",
    "template = '''\n",
    "Answer the following questions in GERMAN as best you can.\n",
    "Questions: {q}\n",
    "'''\n",
    "\n",
    "# Create a PromptTemplate object from the template\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Pull the react prompt from the hub\n",
    "prompt = hub.pull('hwchase17/react')\n",
    "\n",
    "# displaying information about the react prompt\n",
    "# print(type(prompt))\n",
    "# print(prompt.input_variables)\n",
    "# print(prompt.template)\n",
    "\n",
    "# 1. Python REPL Tool (for executing Python code)\n",
    "python_repl = PythonREPLTool()\n",
    "python_repl_tool = Tool(\n",
    "    name='Python REPL',\n",
    "    func=python_repl.run,\n",
    "    description='Useful when you need to use Python to answer a question. You should input Python code.'\n",
    ")\n",
    "\n",
    "# 2. Wikipedia Tool (for searching Wikipedia)\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wikipedia_tool = Tool(\n",
    "    name='Wikipedia',\n",
    "    func=wikipedia.run,\n",
    "    description='Useful for when you need to look up a topic, country, or person on Wikipedia.'\n",
    ")\n",
    "\n",
    "# 3. DuckDuckGo Search Tool (for general web searches)\n",
    "search = DuckDuckGoSearchRun()\n",
    "duckduckgo_tool = Tool(\n",
    "    name='DuckDuckGo Search',\n",
    "    func=search.run,\n",
    "    description='Useful for when you need to perform an internet search to find information that another tool can\\'t provide.'\n",
    ")\n",
    "\n",
    "# Combine the tools into a list\n",
    "tools = [python_repl_tool, wikipedia_tool, duckduckgo_tool]\n",
    "\n",
    "# Create a react agent with the ChatOpenAI model, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Initialize the AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about Napoleon Bonaparte's early life in German.\n",
      "Action: Wikipedia\n",
      "Action Input: \"Napoleon Bonaparte frühes Leben\"\u001b[0m\u001b[33;1m\u001b[1;3mPage: Neuenwalde Convent\n",
      "Summary: The Neuenwalde Convent (N. Low Saxon: Klooster Niewohl, German: Kloster Neuenwalde; Latin: Conventus Sanct[a]e Crucis) is a Lutheran damsels' convent in Neuenwalde, a locality of Geestland, Lower Saxony, Germany.\n",
      "Since 1683 the convent is owned by the corporation of the Bremian Knighthood and used for Lutheran conventuals and continues to function as such today. It is the only convent preserved in the Elbe-Weser triangle out of a former sample of 14 monasteries. The convent was established as a Roman Catholic nunnery in 1219, and was recorded in 1282 for pursuing the Benedictine observance. The convent relocated twice in 1282 and 1334.\u001b[0m\u001b[32;1m\u001b[1;3mThis is not the information I was looking for. Let me try again.\n",
      "Action: Wikipedia\n",
      "Action Input: \"Napoleon Bonaparte\"\u001b[0m\u001b[33;1m\u001b[1;3mPage: Napoleon\n",
      "Summary: Napoleon Bonaparte (born Napoleone di Buonaparte; 15 August 1769 – 5 May 1821), later known by his regnal name Napoleon I, was a French general and statesman who rose to prominence during the French Revolution and led a series of military campaigns across Europe during the French Revolutionary and Napoleonic Wars from 1796 to 1815. He led the French Republic as First Consul from 1799 to 1804, then ruled the French Empire as Emperor of the French from 1804 to 1814, and briefly again in 1815. He was King of Italy from 1805 to 1814 and Protector of the Confederation of the Rhine from 1806 to 1813.\n",
      "Born on the island of Corsica to a family of Italian origin, Napoleon moved to mainland France in 1779 and was commissioned as an officer in the French Royal Army in 1785. He supported the French Revolution in 1789 and promoted its cause in Corsica. He rose rapidly through the ranks after winning the siege of Toulon in 1793 and defeating royalist insurgents in Paris on 13 Vendémiaire in 1795. In 1796 he commanded a military campaign against the Austrians and their Italian allies in the War of the First Coalition, scoring decisive victories and becoming a national hero. He led an invasion of Egypt and Syria in 1798 which served as a springboard to political power. In November 1799 Napoleon engineered the Coup of 18 Brumaire against the French Directory and became First Consul of the Republic. He won the Battle of Marengo in 1800, which secured France's victory in the War of the Second Coalition, and in 1803 he sold the territory of Louisiana to the United States. In December 1804 Napoleon crowned himself Emperor of the French, further expanding his power.\n",
      "The breakdown of the Treaty of Amiens led to the War of the Third Coalition by 1805. Napoleon shattered the coalition with a decisive victory at the Battle of Austerlitz, which led to the dissolution of the Holy Roman Empire. In the War of the Fourth Coalition, Napoleon defeated Prussia at the Battle of Jena–Auerstedt in 1806, marched his Grande Armée into Eastern Europe, and defeated the Russians in 1807 at the Battle of Friedland. Seeking to extend his trade embargo against Britain, Napoleon invaded the Iberian Peninsula and installed his brother Joseph as King of Spain in 1808, provoking the Peninsular War. In 1809 the Austrians again challenged France in the War of the Fifth Coalition, in which Napoleon solidified his grip over Europe after winning the Battle of Wagram. In the summer of 1812 he launched an invasion of Russia, briefly occupying Moscow before conducting a catastrophic retreat of his army that winter. In 1813 Prussia and Austria joined Russia in the War of the Sixth Coalition, in which Napoleon was decisively defeated at the Battle of Leipzig. The coalition invaded France and captured Paris, forcing Napoleon to abdicate in April 1814. They exiled him to the Mediterranean island of Elba and restored the Bourbons to power. Ten months later, Napoleon escaped from Elba on a brig, landed in France with a thousand men, and marched on Paris, again taking control of the country. His opponents responded by forming a Seventh Coalition, which defeated him at the Battle of Waterloo in June 1815. Napoleon was exiled to the remote island of Saint Helena in the South Atlantic, where he died of stomach cancer in 1821, aged 51.\n",
      "Napoleon is considered one of the greatest military commanders in history, and Napoleonic tactics are still studied at military schools worldwide. His legacy endures through the modernizing legal and administrative reforms he enacted in France and Western Europe, embodied in the Napoleonic Code. He established a system of public education, abolished the vestiges of feudalism, emancipated Jews and other religious minorities, abolished the Spanish Inquisition, enacted the principle of equality before the law for an emerging middle class, and centralized state power at the expense of religious authorities. His conquests acted as a catalyst f\u001b[0m\u001b[32;1m\u001b[1;3mI found the information about Napoleon Bonaparte's early life in German.\n",
      "Final Answer: Napoleon Bonaparte wurde am 15. August 1769 auf der Insel Korsika geboren und zog 1779 nach Frankreich. Er wurde 1785 zum Offizier in der französischen Armee ernannt und stieg schnell in den Rängen auf.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# question = 'Generate the first 20 numbers in the Fibonacci series.'\n",
    "# question = 'Who is the current prime minister of the UK?'\n",
    "question = 'Tell me about Napoleon Bonaparte early life'\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the following questions in GERMAN as best you can.\n",
      "Questions: Tell me about Napoleon Bonaparte early life\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Napoleon Bonaparte wurde am 15. August 1769 auf der Insel Korsika geboren und zog 1779 nach Frankreich. Er wurde 1785 zum Offizier in der französischen Armee ernannt und stieg schnell in den Rängen auf.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
